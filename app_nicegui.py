from ast import Dict
from time import sleep
import asyncio
import os
from dotenv import load_dotenv
from pathlib import Path
from nicegui import app, ui
from langchain_core.messages import HumanMessage
from utils.build_config_id import build_config_id
from graph.state import BrickState
from graph.builder import build_graph_with_interaction
from utils.save_dir_name import get_save_dir

# åŠ è½½ç¯å¢ƒå˜é‡
config_file = Path(__file__).parent / 'graph' / 'brick_test_config.env'
load_dotenv(dotenv_path=str(config_file))
PROJECT_ROOT = os.getenv('PROJECT_ROOT', os.path.abspath(os.path.dirname(__file__)))
"""
ç»„ä»¶ï¼š
ä¸Šæ–¹çš„èœå•æ 
å·¦ä¾§å¯¹è¯æ¡†
å³ä¾§æ“ä½œå°
ä¸‹æ–¹è¾“å…¥æ–‡æœ¬æ¡†
æ–‡æœ¬æ¡†å³ä¾§é‡ç½®æŒ‰é’®
"""


ui.query('body').style('margin: 0; padding: 0; overflow: hidden;')

# æ·»åŠ  iMessage é£æ ¼çš„åŠ¨ç”»
ui.add_head_html('''
<style>
@keyframes slideInFade {
    from {
        opacity: 0;
        transform: translateY(20px) scale(0.95);
    }
    to {
        opacity: 1;
        transform: translateY(0) scale(1);
    }
}
</style>
''')

# ä¸»å®¹å™¨:å æ»¡æ•´ä¸ªè§†å£
with ui.column().style('width: 100vw; height: 100vh; margin: 0; padding: 0;'):
    
    # === åŠ è½½æç¤ºæ‚¬æµ®æ¡†ï¼ˆå°å·§é€æ˜åœ†è§’ï¼Œåˆå§‹éšè—ï¼‰ ===
    loading_banner = ui.element('div').style(
        'display: none; position: fixed; bottom: 120px; left: 50%; '
        'transform: translateX(-50%); '
        'background: rgba(25, 118, 210, 0.9); color: white; '
        'padding: 16px 24px; border-radius: 24px; '
        'box-shadow: 0 4px 12px rgba(0,0,0,0.15); '
        'backdrop-filter: blur(10px); z-index: 9999;'
    )
    with loading_banner:
        with ui.row().style('align-items: center; gap: 12px;'):
            ui.spinner(size='sm', color='white')
            ui.label('æ™ºèƒ½ä½“è¿è¡Œä¸­ï¼Œè¯·ç¨å€™...').style('color: white; font-weight: 500; font-size: 14px;')
    
    # === é¡¶æ  ===
    with ui.row().style(
        'height: 10%; min-height: 60px; width: 100%; '
        'align-items: center; padding: 0 24px; '
        'border-bottom: 1px solid #ddd; background: #f5f5f5;'
    ):
        ui.icon('science', size='md')
        ui.label('BRICK Agent').style('font-size: 24px; font-weight: bold; margin-left: 12px;')
        ui.space()
        ui.label('Demo Layout').style('font-size: 14px; color: #888;')

    # === ä¸­é—´åŒºåŸŸ===
    with ui.element('div').style(
        'height: 75%; width: 100%; margin: 0 auto; display: flex; flex-direction: row;'
    ):
        
        # å·¦ä¾§:å¯¹è¯åŒº
        with ui.element('div').style(
            'width: 50%; height: 100%; padding: 16px; '
            'border-right: 1px solid #ddd; display: flex; flex-direction: column;'
        ):
            ui.label('ğŸ’¬ å¯¹è¯').style('font-size: 18px; font-weight: 600; margin-bottom: 8px;')
            biomics_chat = ui.scroll_area().style('width: 100%; flex: 1;')


        
        # å³ä¾§:ä»£ç åŒº
        with ui.element('div').style(
            'width: 50%; height: 100%; padding: 16px; display: flex; flex-direction: column;'
        ):
            ui.label('ğŸ§¾ ä»£ç ').style('font-size: 18px; font-weight: 600; margin-bottom: 8px;')
            biomics_co_pilot = ui.scroll_area().style('width: 100%; flex: 1;')


    # === åº•éƒ¨å¯¹è¯æ  ===
    with ui.row().style(
        'height: 10%; min-height: 60px; width: 100%; '
        'align-items: center; padding: 0 24px; gap: 12px; '
        'border-top: 1px solid #ddd;'
    ):
        # å·¦ä¾§:ä¸Šä¼ å›¾æ ‡ + æ–‡ä»¶å
        with ui.row().style('align-items: center; gap: 4px;'):
            # éšè—çš„ä¸Šä¼ æ§ä»¶
            file_upload = ui.upload(
                auto_upload=True,
            ).style('display: none;')  # å®Œå…¨éšè—
            
            # æ˜¾ç¤ºçš„å›¾æ ‡æŒ‰é’®ï¼Œç‚¹å‡»æ—¶è§¦å‘ä¸Šä¼ 
            upload_button = ui.button(icon='file_upload', on_click=lambda: file_upload.run_method('pickFiles')).props('flat round dense')
            
            # æ–‡ä»¶åæ ‡ç­¾
            upload_name_label = ui.label('').style(
                'font-size: 12px; color: #666; max-width: 200px; '
                'overflow: hidden; text-overflow: ellipsis; white-space: nowrap;'
            )
        
        # ä¸­é—´:è¾“å…¥æ¡†
        user_input = ui.input(placeholder='è¯·è¾“å…¥æ¶ˆæ¯æˆ–æŒ‡ä»¤...').style('flex: 1;')
        
        # å³ä¾§:é‡ç½®æŒ‰é’®
        reset_button = ui.button('é‡ç½®', icon='restart_alt').props('outlined')

"""
å‡½æ•°ï¼š
1. å¯¹è¯åŒºï¼Œæ ¹æ®eventæ›´æ–°å‘å¯¹è¯åŒºæ·»åŠ ä¿¡æ¯
2. ä»£ç åŒºï¼Œæ ¹æ®eventæ›´æ–°å³ä¾§çš„copilot
3. é‡ç½®é¡µé¢æŒ‰é’®å¯¹åº”å‡½æ•°ï¼Œæ¸…é™¤é¡µé¢å†…å®¹
4. 

"""
UPLOAD_DIR = os.path.join(PROJECT_ROOT, 'data')

def set_graph_running(is_running: bool) -> None:
    """ç»Ÿä¸€æ§åˆ¶å›¾æ˜¯å¦åœ¨è¿è¡Œï¼Œä»¥åŠç›¸å…³æ§ä»¶çš„å¯ç”¨çŠ¶æ€"""
    app.storage.client['graph_running'] = is_running
    
    if is_running:
        # ç¦ç”¨è¾“å…¥ä¸ä¸Šä¼ 
        user_input.props('disable')
        upload_button.props('disable')
        
        # æ˜¾ç¤ºé¡¶éƒ¨åŠ è½½æ¨ªå¹…
        loading_banner.style('display: flex;')
    else:
        # æ¢å¤è¾“å…¥ä¸ä¸Šä¼ 
        user_input.props(remove='disable')
        upload_button.props(remove='disable')
        
        # éšè—é¡¶éƒ¨åŠ è½½æ¨ªå¹…
        loading_banner.style('display: none;')

def save_uploaded_file(e) -> str:
    """ä¿å­˜ä¸Šä¼ æ–‡ä»¶åˆ°å›ºå®šç›®å½•ï¼Œå¹¶è¿”å›ä¿å­˜è·¯å¾„"""
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    # NiceGUI çš„ UploadEventArguments: æ–‡ä»¶ååœ¨ e.nameï¼Œå†…å®¹åœ¨ e.content
    # å¦‚æœ e.name ä¸å­˜åœ¨ï¼Œå°è¯•ä» content è·å–
    try:
        file_name = e.name
    except AttributeError:
        # å¦‚æœæ²¡æœ‰ name å±æ€§ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å
        file_name = getattr(e, 'filename', 'uploaded_file.h5ad')
    
    save_path = os.path.join(UPLOAD_DIR, file_name)
    with open(save_path, 'wb') as f:
        f.write(e.content.read())
    return save_path
async def handle_file_upload(e) -> None:
    """ä¸Šä¼ äº‹ä»¶å›è°ƒï¼šä¿å­˜æ–‡ä»¶å¹¶æ›´æ–°å›¾æ ‡æ—æ–‡å­—"""
    
    # å¦‚æœå›¾æ­£åœ¨è¿è¡Œï¼Œç¦æ­¢ä¸Šä¼ 
    if app.storage.client.get('graph_running', False):
        ui.notify('å½“å‰ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œæš‚æ—¶ä¸èƒ½ä¸Šä¼ æ–‡ä»¶', type='warning')
        return
    
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    
    # NiceGUI çš„ SmallFileUpload å¯¹è±¡ï¼Œread() æ˜¯å¼‚æ­¥æ–¹æ³•
    file_name = e.file.name
    file_content = await e.file.read()  # å¿…é¡» await
    
    # ä¿å­˜æ–‡ä»¶
    save_path = os.path.join(UPLOAD_DIR, file_name)
    with open(save_path, 'wb') as f:
        f.write(file_content)
    
    # æ›´æ–°å³ä¾§çš„å°æ–‡å­—ä¸ºæ–‡ä»¶å
    upload_name_label.text = os.path.basename(save_path)
    # æŠŠè·¯å¾„å­˜åˆ° client storageï¼Œåç»­ start_graph æ—¶å¯ä»¥ä½¿ç”¨
    app.storage.client['uploaded_file_path'] = save_path
    # å›¾æ ‡å˜æˆç»¿è‰²æ‰“å‹¾ï¼Œæç¤ºä¸Šä¼ æˆåŠŸ
    upload_button.props('icon=check_circle color=positive')
    ui.notify(f'æ–‡ä»¶å·²ä¸Šä¼ : {os.path.basename(save_path)}', type='positive')
def agent_update_chat(event) -> None:
    """
    supervisor
    env_checker
    general_responder
    data_analyzer
    analyze_planner
    planner
    plan_executor
    coder
    code_runner
    code_debugger
    responder 
    notebook_searcher
    """

    
    agent_name = event.get('agent')   
    agent_thought = ""
    agent_output = ""
    
    # æ·»åŠ åŠ¨ç”»æ ·å¼ï¼šæ¨¡ä»¿ iMessage
    message_animation = '''
        opacity: 0;
        animation: slideInFade 0.4s ease-out forwards;
    '''
    
    if agent_name=="supervisor":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=[agent_thought, agent_output], name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)  # æ»šåŠ¨åˆ°åº•éƒ¨
    elif agent_name=="env_checker":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=[agent_thought, agent_output], name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="data_analyzer":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=[agent_thought, agent_output], name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="analyze_planner":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=[agent_thought, agent_output], name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="planner":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=agent_thought, name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="plan_executor":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=agent_thought, name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="coder":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=agent_thought, name=agent_name).style(message_animation)
            with ui.chat_message(name=agent_name):
                ui.code(agent_output)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="code_runner":
        pf = event.get('process_flag')
        if pf==1:
            ui.chat_message(text="Code execution completed.Ready to process the next step.", name=agent_name).style(message_animation)
        else:
            ui.chat_message(text="Code execution failed.Ready to debug.", name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="code_debugger":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=agent_thought, name=agent_name).style(message_animation)
            with ui.chat_message(name=agent_name):
                ui.code(agent_output)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="responder":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=[agent_thought, agent_output], name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    elif agent_name=="notebook_searcher":
        pass
    elif agent_name=="general_responder":
        agent_thought = event.get('thought')
        agent_output = event.get('output')
        with biomics_chat:
            ui.chat_message(text=[agent_thought, agent_output], name=agent_name).style(message_animation)
        biomics_chat.scroll_to(percent=1.0)
    else:
        print("æœªè·å–åˆ°", agent_name)
def start_graph(question: str, file_path: str, config: dict, save_dir: str = None):
    state_data = {
        "question": question,
        "messages": [HumanMessage(content=question)],
    }
    if file_path:
        state_data["data_path"] = file_path
    if save_dir:
        state_data["save_dir"] = save_dir
    initial_state = BrickState(**state_data)
    graph = build_graph_with_interaction(interrupt_after=["env_checker","data_analyzer"],interrupt_before=[])
    initial_state_dict = initial_state.model_dump()
    events = graph.stream(initial_state_dict, config=config, stream_mode="values")
    return events, graph
def process_events(graph, events, config):
    """å¾ªç¯æ¶ˆè´¹ eventsï¼Œç›´åˆ°é‡åˆ°ä¸­æ–­æˆ– FINISHED
    è¿”å›å€¼: (waiting_kind, graph) å…ƒç»„
    - waiting_kind: None / 'update_data_info' / 'update_data_repo'
    - graph: æ›´æ–°åçš„ graph å®ä¾‹
    """
    for event in events:
        status = event.get("status")
        agent_update_chat(event)  # ç»Ÿä¸€æ›´æ–°ç•Œé¢

        if status == "AWAITING_CONFIRMATION":
            # env_checker éœ€è¦ update_data_infoï¼šåœ¨ UI ä¸Šæç¤ºï¼Œå¹¶è®°å½•â€œç­‰å¾…ç±»å‹â€
            print("[DEBUG] process_events è¿”å› waiting_kind = 'update_data_info'")
            return ('update_data_info', graph)

        elif status == "Revise":
            # data_analyzer éœ€è¦ update_data_repo
            print("[DEBUG] process_events è¿”å› waiting_kind = 'update_data_repo'")
            return ('update_data_repo', graph)

        elif status == "VALIDATED":
            # æ ¹æ®é¡¹ç›®è®°å¿†ï¼šVALIDATED ä¹Ÿéœ€è¦æ‰‹åŠ¨ç»§ç»­ stream
            events = graph.stream(None, config=config, stream_mode="values")
            first_event = next(events, None)
            return process_events(graph, events, config)

        elif status == "NOT_FINISHED":
            continue

        elif status == "FINISHED":
            user_question = event.get("question")
            if event.get("agent")=='general_responder':
                with biomics_chat:
                    with ui.card():
                        with ui.row().props('no-wrap').style('align-items: center;'):
                            ui.label(f"æ‚¨çš„é—®é¢˜â€œ{user_question}â€ä¸åœ¨æˆ‘ä»¬èƒ½åŠ›èŒƒå›´å†…ï¼Œè¯•è¯•è®©æˆ‘ä»¬åšç»†èƒæ³¨é‡Šã€åŸºå› å¯Œé›†ç­‰ä»»åŠ¡ï¼Ÿ")
                        with ui.row().props('no-wrap').style('align-items: center;'):
                            ui.button('é‡æ–°æé—®', on_click=lambda: reset_button.run_method('click')).props('flat round dense')
            elif event.get('agent')=='responder':
                with biomics_chat:
                    with ui.card():
                        with ui.row().props('no-wrap').style('align-items: center;'):
                            ui.label(f"æ‚¨çš„ä»»åŠ¡éœ€æ±‚â€œ{user_question}â€å·²å®Œæˆï¼Œæ­¤ä¼šè¯å°†å·²ç»“æŸ")
                        with ui.row().props('no-wrap').style('align-items: center;'):
                            ui.button('é‡æ–°æé—®', on_click=lambda: reset_button.run_method('click')).props('flat round dense')
            return (None, graph)
    
    # å¦‚æœ events æ¶ˆè´¹å®Œæ²¡æœ‰ä»»ä½•ç‰¹æ®ŠçŠ¶æ€ï¼Œè¿”å› None
    return (None, graph)
async def handle_user_input():
    """ç»Ÿä¸€å¤„ç†ç”¨æˆ·è¾“å…¥ï¼š
    - æ²¡æœ‰ç­‰å¾…çŠ¶æ€æ—¶ï¼Œä½œä¸ºæ–°é—®é¢˜å¯åŠ¨ä¸€æ¡å›¾
    - ç­‰å¾…çŠ¶æ€ä¸º AWAITING_CONFIRMATION / Revise æ—¶ï¼Œä½œä¸ºåé¦ˆæˆ–ä¿®æ”¹ç»§ç»­å›¾
    """

    text = (user_input.value or '').strip()
    if not text:
        ui.notify('è¯·è¾“å…¥å†…å®¹', type='warning')
        return
    with biomics_chat:
        ui.chat_message(text=text, name='user', sent=True).style('margin-left: auto; max-width: 80%;')
    biomics_chat.scroll_to(percent=1.0)  # ç”¨æˆ·æ¶ˆæ¯ä¹Ÿæ»šåŠ¨åˆ°åº•éƒ¨
    # æ¸…ç©ºè¾“å…¥æ¡†ï¼ˆé˜²æ­¢é‡å¤å‘é€ï¼‰
    user_input.value = ''

    # å¦‚æœæœ‰åå°ä»»åŠ¡è¿˜åœ¨è·‘ï¼Œå…ˆç­‰å®ƒå®Œæˆï¼ˆç¡®ä¿ waiting_kind å·²ç»è¢«æ­£ç¡®è®¾ç½®ï¼‰
    current_task = app.storage.client.get('background_task')
    if current_task and not current_task.done():
        try:
            await current_task
        except:
            pass  # å¿½ç•¥åå°ä»»åŠ¡å¼‚å¸¸
    
    # è¯»å–å½“å‰ä¼šè¯çŠ¶æ€ï¼šæ˜¯å¦åœ¨ç­‰å¾…æŸç±»ä¸­æ–­è¾“å…¥
    waiting_kind = app.storage.client.get('waiting_kind')
    is_running = app.storage.client.get('graph_running', False)
    print(f"[DEBUG] handle_user_input è¯»å–çŠ¶æ€: waiting_kind={waiting_kind}, is_running={is_running}")

    # ============= æƒ…å†µä¸€ï¼šå½“å‰æ²¡æœ‰ç­‰å¾…ä¸­æ–­è¾“å…¥ï¼Œè§†ä¸ºâ€œæ–°é—®é¢˜â€ =============
    if not waiting_kind:
        if is_running:
            ui.notify('å½“å‰å·²æœ‰ä»»åŠ¡åœ¨æ‰§è¡Œï¼Œè¯·ç¨å€™å†æé—®', type='warning')
            return
        # ä¸ºæœ¬æ¬¡ä¼šè¯ç”Ÿæˆ configï¼ˆä½¿ç”¨ç‹¬ç«‹ thread_idï¼‰
        thread_id = build_config_id()
        config = {"configurable": {"thread_id": thread_id}}

        try:
            set_graph_running(True)

            # å¯åŠ¨ä¸€æ¬¡å›¾ï¼ˆå¦‚æœæœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œåˆ™ä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„ï¼‰
            uploaded_file = app.storage.client.get('uploaded_file_path', '')
            events, graph = start_graph(
                question=text,
                file_path=uploaded_file,
                config=config,
                save_dir=thread_id,
            )

            # å­˜å‚¨ graph å’Œ configï¼Œæ–¹ä¾¿ä¸­æ–­åç»§ç»­ä½¿ç”¨
            app.storage.client['graph'] = graph
            app.storage.client['config'] = config

            # äº¤ç»™ç»Ÿä¸€çš„äº‹ä»¶å¤„ç†é€»è¾‘ï¼ˆåå°çº¿ç¨‹æ‰§è¡Œï¼Œé¿å…é˜»å¡UIï¼‰
            task = asyncio.create_task(asyncio.to_thread(process_events, graph, events, config))
            app.storage.client['background_task'] = task
            result = await task
            
            # åå°çº¿ç¨‹è¿”å›çš„çŠ¶æ€ï¼Œç”±ä¸»çº¿ç¨‹è®¾ç½®åˆ° app.storage.client
            if result:
                waiting_kind, graph = result
                app.storage.client['graph'] = graph
                app.storage.client['config'] = config
                if waiting_kind:
                    app.storage.client['waiting_kind'] = waiting_kind
                    set_graph_running(False)
                    print(f"[DEBUG] ä¸»çº¿ç¨‹è®¾ç½® waiting_kind = {waiting_kind}")
                else:
                    set_graph_running(False)

        except Exception as e:
            error_msg = f"âŒ å¯åŠ¨ä»»åŠ¡å¤±è´¥ï¼š{e}"
            with biomics_chat:
                ui.chat_message(text=error_msg, name='ç³»ç»Ÿ')
            ui.notify(error_msg, type='negative')
        finally:
            # æ˜¯å¦ç½®å› Falseï¼Œè¦çœ‹ process_events æ˜¯å¦è¿›å…¥ç­‰å¾…çŠ¶æ€
            # è¿™é‡Œä»…åœ¨æ²¡æœ‰ç­‰å¾…æ ‡è®°æ—¶é‡ç½®
            if not app.storage.client.get('waiting_kind'):
                set_graph_running(False)

        return

    # ============= æƒ…å†µäºŒï¼šæ­£åœ¨ç­‰å¾…ä¸­æ–­èŠ‚ç‚¹è¾“å…¥ï¼ˆAWAITING_CONFIRMATION / Reviseï¼‰ =============
    # ç­‰å¾…è¾“å…¥æ—¶ï¼Œä¸å…è®¸æ–°çš„é—®é¢˜ï¼Œtext è¢«è§†ä¸ºå¯¹æ–¹æ¡ˆçš„â€œç¡®è®¤/ä¿®æ”¹â€åé¦ˆ
    try:
        graph = app.storage.client.get('graph')
        config = app.storage.client.get('config')
        if graph is None or config is None:
            ui.notify('å†…éƒ¨çŠ¶æ€ä¸¢å¤±ï¼Œè¯·é‡æ–°å¼€å§‹ä¼šè¯', type='negative')
            return


        if waiting_kind == 'update_data_info':
            print("[DEBUG] è¿›å…¥ update_data_info åˆ†æ”¯")
            graph.update_state(config=config, values={'update_data_info': text})
            app.storage.client['waiting_kind'] = None
            set_graph_running(True)
            events = graph.stream(None, config=config, stream_mode='values')
            first_event = next(events, None)
            task = asyncio.create_task(asyncio.to_thread(process_events, graph, events, config))
            app.storage.client['background_task'] = task
            result = await task
            
            # åå°çº¿ç¨‹è¿”å›çš„çŠ¶æ€ï¼Œç”±ä¸»çº¿ç¨‹è®¾ç½®
            if result:
                waiting_kind, graph = result
                app.storage.client['graph'] = graph
                app.storage.client['config'] = config
                if waiting_kind:
                    app.storage.client['waiting_kind'] = waiting_kind
                    set_graph_running(False)
                else:
                    set_graph_running(False)

        elif waiting_kind == 'update_data_repo':
            print("[DEBUG] è¿›å…¥ update_data_repo åˆ†æ”¯")
            graph.update_state(config=config, values={'update_data_repo': text})
            app.storage.client['waiting_kind'] = None
            set_graph_running(True)
            events = graph.stream(None, config=config, stream_mode='values')
            first_event = next(events, None)
            task = asyncio.create_task(asyncio.to_thread(process_events, graph, events, config))
            app.storage.client['background_task'] = task
            result = await task
            
            # åå°çº¿ç¨‹è¿”å›çš„çŠ¶æ€ï¼Œç”±ä¸»çº¿ç¨‹è®¾ç½®
            if result:
                waiting_kind, graph = result
                app.storage.client['graph'] = graph
                app.storage.client['config'] = config
                if waiting_kind:
                    app.storage.client['waiting_kind'] = waiting_kind
                    set_graph_running(False)
                else:
                    set_graph_running(False)
        else:
            ui.notify(f'æœªçŸ¥ç­‰å¾…çŠ¶æ€ï¼š{waiting_kind}', type='negative')
            return

    except Exception as e:
        error_msg = f"âŒ ç»§ç»­æ‰§è¡Œä»»åŠ¡å¤±è´¥ï¼š{e}"
        with biomics_chat:
            ui.chat_message(text=error_msg, name='ç³»ç»Ÿ')
        ui.notify(error_msg, type='negative')
    finally:
        # ä¸ä¸Šé¢ä¸€è‡´ï¼Œä»…å½“æ²¡æœ‰æ–°çš„ç­‰å¾…çŠ¶æ€æ—¶ï¼Œè®¤ä¸ºä»»åŠ¡ç»“æŸ
        if not app.storage.client.get('waiting_kind'):
            set_graph_running(False)
def reset_agent():
    """æ¸…ç©ºç•Œé¢å¹¶é‡ç½®ä¼šè¯ç›¸å…³çš„ session çŠ¶æ€"""

    biomics_chat.clear()
    biomics_co_pilot.clear()

    set_graph_running(False)
    app.storage.client['waiting_kind'] = None

    # ä¸ºæ–°çš„ä¼šè¯ç”Ÿæˆä¸€ä¸ª thread_idï¼ˆ5 ä½æ•°å­—å­—ç¬¦ä¸²ï¼‰
    app.storage.client['thread_id'] = ''


if __name__ in {"__main__", "__mp_main__"}:
    file_upload.on_upload(handle_file_upload)
    user_input.on('keydown.enter', handle_user_input)
    reset_button.on_click(reset_agent)
    ui.run()
